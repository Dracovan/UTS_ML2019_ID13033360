{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 1 - A1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dracovan/UTS_ML2019_ID13033360/blob/master/Assignment_1_A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "866XgBRFY8Tm",
        "colab_type": "text"
      },
      "source": [
        "# Title: Assignment 1: Understanding The Literature\n",
        "\n",
        "[link text](https://github.com/hugh-armstrong/UTS_ML2019_ID13033360)\n",
        "\n",
        "Introduction\n",
        "\n",
        "# Content (300) 340\n",
        "\n",
        "This paper aims to solve the problem of facial recognition under both different lighting conditions and with different facial expressions. Their approach is to take the images and reduce the dimensionality of them through linear projection. They look at 3 different methodologies along with their own to achieve their goal. These are Eigenface and Eigenface w/o 1st 3, correlation, linear subspace and their method based on Fishers Linear Discrimination Fisherface.\n",
        "\n",
        "The first and simplest classifier they use is Correlation. It identifies similarity by measuring the difference in the point on both the test and learning set. There are three main disadvantages of using this method. When there are different lighting conditions the points in the test set will not be closely clustered, its computationally expensive and it requires a large amount of storage. \n",
        "\n",
        "Eigenfaces tries to solve the last two disadvantages of the last method by reducing dimensionality through Principal Component Analysis (PCA). This Karhunen-Loeve method finds a linear projection method that maximises scatter. This is then classified using nearest neighbour. The main issue that is that scatter can be created by not only different faces which is useful but also by the same face in different lighting conditions which is problematic. A variant of this method is explored by discarding the three most significant components to alleviate this.\n",
        "\n",
        "The third method that they explore is the use of linear subspaces. This method uses the idea that diffusely reflective surfaces without shadowing lie on a 3D linear subspace. Using 3 images from the same direction with independent light source directions the level of reflection can be obtained.  This combination of 3 images provides a linear subspace of a high dimensional image space. However, while this model allows works well under different lighting conditions if there are parts of the face that change or are self-shadowing the accuracy declines.\n",
        "\n",
        "The method that they have put forward is Fisherface. This uses class specific linear methods for dimensionality reduction. This tries to maximise the difference between classes to make the classification more reliable.\n",
        "\n",
        "# Innovation (300) 253\n",
        "\n",
        "This paper explores a new methodology of data representation for facial recognition to try to overcome the limitation of lighting and expression that hindered previous methodologies. Previous methodologies for facial recognition found it difficult to maintain accuracy under different lighting conditions and expressions. To overcome these challenges, they based their method off two observations. That images taken from a fixed viewpoint that have surfaces which diffusely reflected light regardless of direction lie on a 3D linear subspace and that this assumption starts to fail when shadowing from facial features and facial expressions occur.\t\n",
        "\n",
        "To achieve this a new method based on Fisher’s linear discriminant is explored. Previous methods show that linear separability can be maintained when reducing dimensionality through linear projection. So, this paper argues that using class specific linear methods for dimensionality reduction with simple classifiers in a dimensionally reduce form should lead to more accurate results. This is then compared to the previous methodologies with the result being that it is indeed more effective than previous methods.\n",
        "\n",
        "This paper has a clear goal and a methodology that builds on previous foundational concepts as well as ideas from other disciplines. This broad approach allows for the infusion of new but well understood concepts. The taxonomic classifier first developed by Robert Fisher clearly provided the inspiration for the research. However, the dataset that they used may not have been varied enough due to its size to accurately predict distinctions between people with similar facial structures or those with different shades of skin tone.\n",
        "\n",
        "# Technical Quality (200) 208\n",
        "\n",
        "For the most part throughout the paper the technical quality is quite high with the quality of the work for the most part well done. The methods tested had all of their equations defined and well explained, with particular attention to the model that they were developing. Fig. 2 was used to explain the linear subspace comparison and give a visual representation of the model, this clearly expressed how their new method would compare to principal component analysis. How the lighting has affected the participants face was clearly demonstrated, however the number of samples for each subset was on the small side. The table in figure 5 however was poor as it explored the same subset as it was extrapolating from and also didn’t use the larger but more challenging subsets four and five. So, while the Fisherface has the lowest error rate in those subsets it may decline dramatically in the subsets 4 and 5 which are not shown.\n",
        "\tWith the information given in the paper they could in probability be replicated with fair accuracy because both the methodology and equations were explained fully. However, without the exact set that they tested their methodology on their may be some variance due to the quality of the images.\n",
        "\n",
        "# Application and X-Factor (200) 199\n",
        "\n",
        "The ideas that this paper proposes are solid, by reducing dimensionality through linear projection a prediction can be made even when some of the points are noisy.  This is could be further developed to allow for other common items worn on the face like the glasses and for different facial structures as well, as there didn’t seem to be any female or African examples. It also could be applied to other types of images identifying different animals, signs and foods. Which could be used in a variety of avenues. The research could also be further developed to include matching of expressions as well. \n",
        "\n",
        "I believe this paper would be thought provoking if discussed in class as it is both easy to see the applications for as well as future uses of this kind of algorithm with data representation learning being applicable to all many areas in machine learning. The areas that I found interesting in this work was how it was able to discern the facial data even with different facial expressions distorting a good portion of the potential data space. Reducing dimensionality in this area with just image data would risk removing the wrong information for the model.\n",
        "\n",
        "# Presentation (100) - 115 \n",
        "\n",
        "The papers overall presentation was clear and logical with some minor mistakes. The paper identifies unsolved problems clearly and lays out how their model would overcome these challenges. The arguments were relatively easy to follow however the paper did have a bit of jargon that could have been rephrased. The visuals in figure 4 give a clear indication of the data set that they used.  The table in Figure 5 extrapolates data from subset one and gives the error rate for the same subset, which is superfluous, it also leaves out subset 4 and 5. The last section around glasses recognition seems tacked as it isn’t mentioned until most of the way through the paper.\n",
        "\n",
        "\n",
        "# References (NEED AT LEAST 5)\n"
      ]
    }
  ]
}